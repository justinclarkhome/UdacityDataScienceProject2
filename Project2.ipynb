{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import csv\n",
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer as wnl\n",
    "\n",
    "sys.path.append('./data')\n",
    "sys.path.append('./models')\n",
    "\n",
    "from process_data import *\n",
    "# from train_classifier import load_data\n",
    "\n",
    "nltk.download('words'); # English word corpus for filtering data\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "## ETL Pipeline: process_data.py\n",
    "In a Python script, process_data.py, write a data cleaning pipeline that:\n",
    "- Loads the messages and categories datasets\n",
    "- Merges the two datasets\n",
    "- Cleans the data\n",
    "- Stores it in a SQLite database\n",
    "\n",
    "## ML pipeline: train_classifier.py\n",
    "In a Python script, train_classifier.py, write a machine learning pipeline that:\n",
    "- Loads data from the SQLite database\n",
    "- Splits the dataset into training and test sets\n",
    "- Builds a text processing and machine learning pipeline\n",
    "- Trains and tunes a model using GridSearchCV\n",
    "- Outputs results on the test set\n",
    "- Exports the final model as a pickle file\n",
    "\n",
    "## Flask Web App\n",
    "We are providing much of the flask web app for you, but feel free to add extra features depending on your knowledge of flask, html, css and javascript. For this part, you'll need to:\n",
    "- Modify file paths for database and model as needed\n",
    "- Add data visualizations using Plotly in the web app. One example is provided for you.\n",
    "\n",
    "## Github and Code Quality\n",
    "Your project will also be graded based on the following:\n",
    "- Use of Git and Github\n",
    "- Strong documentation\n",
    "- Clean and modular code\n",
    "- Follow the [RUBRIC](https://learn.udacity.com/nanodegrees/nd025/parts/cd0018/lessons/e692c8ed-b713-464b-95ac-72d93a35b4fc/concepts/e692c8ed-b713-464b-95ac-72d93a35b4fc-project-rubric) when you work on your project to assure you meet all of the necessary criteria for developing the pipelines and web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "categories_filepath = os.path.join(DATA_DIR, 'disaster_categories.csv')\n",
    "messages_filepath = os.path.join(DATA_DIR, 'disaster_messages.csv')\n",
    "database_filepath = os.path.join(DATA_DIR, 'DisasterResponse.db')\n",
    "\n",
    "df = clean_data(load_data(messages_filepath, categories_filepath))\n",
    "save_data(df, database_filepath=database_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure it works\n",
    "conn = sqlite3.connect(database_filepath)\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "test = pd.read_sql(f'SELECT * from project2', con=conn, index_col='id')\n",
    "conn.close()\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "- The purpose of this project is to identify an efficient way to model emergency messages to determine which are most informative for making a quick disaster response decision. This is important as resources for disaster response are limited and false positives can prevent those resources from being deployed where they are needed most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "- The dataset is raw, containing an identifier along with communication information that can contain an English 'message', a non-English 'original' messge, and a 'genre' (type of communication). This insformation is provided in CSV form.\n",
    "- The content of each row is inconsistent - for example, some of the lines contain more than 4 commas (which would cleanly correspond to the 4 expected fields), some contain consecutive commas (where one of the messages is missing), and some contain quotation marks separating the English and non-English messages.\n",
    "- There is also categorical information stored in a separate CSV, which provides some informative identifiers that are pre-associated with each message (and link by an 'id' field in each set of data).\n",
    "    - This CSV data is further subdivided into key/value pairs separated by a semicolon, e.g. 'id,key1-value1;key2-value2; ...' etc.\n",
    "- **load_data.py** loads the raw message and category information, first splits out the 'id' and the 'categories' key/value pairs, then splits the key/value pairs into columns of data with integer data, and joins each dataset (on 'id') and passes that joined dataframe along for cleaning in the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- **clean_data.py** attempts to separate the Enlish and non-English components of the raw nessage, and stores the processed English-only message as a new field in the data, allowing it to be more easily processed in the machine learning pipeline.\n",
    "- It also converts the 'genre' field into a set of dummies with boolean values (n-1 categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why does 'related' have a max value of 2?\n",
    "df[[label for label, dtype in df.dtypes.items() if dtype in [int, np.int64]]].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Int64Dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
